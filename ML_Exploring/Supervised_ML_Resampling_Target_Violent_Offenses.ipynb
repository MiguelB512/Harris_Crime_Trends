{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a8fabce",
   "metadata": {},
   "source": [
    "# Crime Statistics Resampling Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15acb0",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5926917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68d0ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d7ae30",
   "metadata": {},
   "source": [
    "### Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4009bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('../Resources/CSV/crime_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3acf2ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>Agency_Count</th>\n",
       "      <th>Murder</th>\n",
       "      <th>Rape</th>\n",
       "      <th>Assault</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Larceny</th>\n",
       "      <th>Auto_Theft</th>\n",
       "      <th>Violent_Offenses</th>\n",
       "      <th>NonViolent_Offenses</th>\n",
       "      <th>Total_Crime</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anderson County</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>195</td>\n",
       "      <td>319</td>\n",
       "      <td>749</td>\n",
       "      <td>75</td>\n",
       "      <td>242</td>\n",
       "      <td>1143</td>\n",
       "      <td>1407</td>\n",
       "      <td>57560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anderson County</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>237</td>\n",
       "      <td>259</td>\n",
       "      <td>485</td>\n",
       "      <td>94</td>\n",
       "      <td>283</td>\n",
       "      <td>838</td>\n",
       "      <td>1145</td>\n",
       "      <td>57250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anderson County</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>153</td>\n",
       "      <td>278</td>\n",
       "      <td>536</td>\n",
       "      <td>64</td>\n",
       "      <td>180</td>\n",
       "      <td>878</td>\n",
       "      <td>1078</td>\n",
       "      <td>57569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anderson County</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>198</td>\n",
       "      <td>531</td>\n",
       "      <td>62</td>\n",
       "      <td>105</td>\n",
       "      <td>791</td>\n",
       "      <td>907</td>\n",
       "      <td>57491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anderson County</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>100</td>\n",
       "      <td>249</td>\n",
       "      <td>514</td>\n",
       "      <td>82</td>\n",
       "      <td>125</td>\n",
       "      <td>845</td>\n",
       "      <td>984</td>\n",
       "      <td>57657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            County  Agency_Count  Murder  Rape  Assault  Burglary  Larceny  \\\n",
       "0  Anderson County             3       9    38      195       319      749   \n",
       "1  Anderson County             3       2    44      237       259      485   \n",
       "2  Anderson County             3       2    25      153       278      536   \n",
       "3  Anderson County             3       1     8       96       198      531   \n",
       "4  Anderson County             3       2    23      100       249      514   \n",
       "\n",
       "   Auto_Theft  Violent_Offenses  NonViolent_Offenses  Total_Crime  Population  \n",
       "0          75               242                 1143         1407       57560  \n",
       "1          94               283                  838         1145       57250  \n",
       "2          64               180                  878         1078       57569  \n",
       "3          62               105                  791          907       57491  \n",
       "4          82               125                  845          984       57657  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the year column to not skew data with year count and averages\n",
    "df = df.drop(columns =['Year'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3061bcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>Agency_Count</th>\n",
       "      <th>Murder</th>\n",
       "      <th>Rape</th>\n",
       "      <th>Assault</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Larceny</th>\n",
       "      <th>Auto_Theft</th>\n",
       "      <th>Violent_Offenses</th>\n",
       "      <th>NonViolent_Offenses</th>\n",
       "      <th>Total_Crime</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anderson County</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>195</td>\n",
       "      <td>319</td>\n",
       "      <td>749</td>\n",
       "      <td>75</td>\n",
       "      <td>242</td>\n",
       "      <td>1143</td>\n",
       "      <td>1407</td>\n",
       "      <td>57560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anderson County</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>237</td>\n",
       "      <td>259</td>\n",
       "      <td>485</td>\n",
       "      <td>94</td>\n",
       "      <td>283</td>\n",
       "      <td>838</td>\n",
       "      <td>1145</td>\n",
       "      <td>57250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anderson County</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>153</td>\n",
       "      <td>278</td>\n",
       "      <td>536</td>\n",
       "      <td>64</td>\n",
       "      <td>180</td>\n",
       "      <td>878</td>\n",
       "      <td>1078</td>\n",
       "      <td>57569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anderson County</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>198</td>\n",
       "      <td>531</td>\n",
       "      <td>62</td>\n",
       "      <td>105</td>\n",
       "      <td>791</td>\n",
       "      <td>907</td>\n",
       "      <td>57491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anderson County</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>100</td>\n",
       "      <td>249</td>\n",
       "      <td>514</td>\n",
       "      <td>82</td>\n",
       "      <td>125</td>\n",
       "      <td>845</td>\n",
       "      <td>984</td>\n",
       "      <td>57657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            County  Agency_Count  Murder  Rape  Assault  Burglary  Larceny  \\\n",
       "0  Anderson County             3       9    38      195       319      749   \n",
       "1  Anderson County             3       2    44      237       259      485   \n",
       "2  Anderson County             3       2    25      153       278      536   \n",
       "3  Anderson County             3       1     8       96       198      531   \n",
       "4  Anderson County             3       2    23      100       249      514   \n",
       "\n",
       "   Auto_Theft  Violent_Offenses  NonViolent_Offenses  Total_Crime  Population  \n",
       "0          75               242                 1143         1407       57560  \n",
       "1          94               283                  838         1145       57250  \n",
       "2          64               180                  878         1078       57569  \n",
       "3          62               105                  791          907       57491  \n",
       "4          82               125                  845          984       57657  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the target column values to violent and nonviolent based on their crime\n",
    "x = dict.fromkeys(['Murder', 'Rape', 'Assault'], 'violent_crimes')    \n",
    "df = df.replace(x)\n",
    "\n",
    "x = dict.fromkeys(['Burglary', 'Larceny', 'Auto_Theft'], 'nonviolent_crimes')    \n",
    "df = df.replace(x)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4dc6f",
   "metadata": {},
   "source": [
    "### Split the Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b84c73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency_Count</th>\n",
       "      <th>Murder</th>\n",
       "      <th>Rape</th>\n",
       "      <th>Assault</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Larceny</th>\n",
       "      <th>Auto_Theft</th>\n",
       "      <th>Violent_Offenses</th>\n",
       "      <th>NonViolent_Offenses</th>\n",
       "      <th>Total_Crime</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>195</td>\n",
       "      <td>319</td>\n",
       "      <td>749</td>\n",
       "      <td>75</td>\n",
       "      <td>242</td>\n",
       "      <td>1143</td>\n",
       "      <td>1407</td>\n",
       "      <td>57560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>237</td>\n",
       "      <td>259</td>\n",
       "      <td>485</td>\n",
       "      <td>94</td>\n",
       "      <td>283</td>\n",
       "      <td>838</td>\n",
       "      <td>1145</td>\n",
       "      <td>57250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>153</td>\n",
       "      <td>278</td>\n",
       "      <td>536</td>\n",
       "      <td>64</td>\n",
       "      <td>180</td>\n",
       "      <td>878</td>\n",
       "      <td>1078</td>\n",
       "      <td>57569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>198</td>\n",
       "      <td>531</td>\n",
       "      <td>62</td>\n",
       "      <td>105</td>\n",
       "      <td>791</td>\n",
       "      <td>907</td>\n",
       "      <td>57491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>100</td>\n",
       "      <td>249</td>\n",
       "      <td>514</td>\n",
       "      <td>82</td>\n",
       "      <td>125</td>\n",
       "      <td>845</td>\n",
       "      <td>984</td>\n",
       "      <td>57657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Agency_Count  Murder  Rape  Assault  Burglary  Larceny  Auto_Theft  \\\n",
       "0             3       9    38      195       319      749          75   \n",
       "1             3       2    44      237       259      485          94   \n",
       "2             3       2    25      153       278      536          64   \n",
       "3             3       1     8       96       198      531          62   \n",
       "4             3       2    23      100       249      514          82   \n",
       "\n",
       "   Violent_Offenses  NonViolent_Offenses  Total_Crime  Population  \n",
       "0               242                 1143         1407       57560  \n",
       "1               283                  838         1145       57250  \n",
       "2               180                  878         1078       57569  \n",
       "3               105                  791          907       57491  \n",
       "4               125                  845          984       57657  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummies\n",
    "df = pd.get_dummies(df.drop(columns='County'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2355430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target\n",
    "y = pd.DataFrame(df[\"Violent_Offenses\"])\n",
    "\n",
    "# Create features\n",
    "X = pd.DataFrame(df[['Population', 'Agency_Count','Total_Crime']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c7bf279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Agency_Count</th>\n",
       "      <th>Total_Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.512000e+03</td>\n",
       "      <td>1512.000000</td>\n",
       "      <td>1512.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.124551e+05</td>\n",
       "      <td>4.108466</td>\n",
       "      <td>3320.835317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.111104e+05</td>\n",
       "      <td>5.483518</td>\n",
       "      <td>15661.906562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.800000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.980250e+03</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>65.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.826650e+04</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.019575e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1068.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.799254e+06</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>197686.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Population  Agency_Count    Total_Crime\n",
       "count  1.512000e+03   1512.000000    1512.000000\n",
       "mean   1.124551e+05      4.108466    3320.835317\n",
       "std    4.111104e+05      5.483518   15661.906562\n",
       "min    8.800000e+01      1.000000       0.000000\n",
       "25%    5.980250e+03      2.000000      65.750000\n",
       "50%    1.826650e+04      3.000000     313.000000\n",
       "75%    5.019575e+04      4.000000    1068.750000\n",
       "max    4.799254e+06     45.000000  197686.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21430534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Violent_Offenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Violent_Offenses\n",
       "0               242\n",
       "1               283\n",
       "2               180\n",
       "3               105\n",
       "4               125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acbba850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1134, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6e2bcd",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cc7376",
   "metadata": {},
   "source": [
    "### Naive Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ede28de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "\n",
    "# resampling\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "895c37f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Violent_Offenses': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dea0054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "419867a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Prediction\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93f58e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1b6ebc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 3, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97af341b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.00      0.00      1.00      0.00      0.00      0.00      19.0\n",
      "          1       0.00      0.00      1.00      0.00      0.00      0.00      17.0\n",
      "          2       0.00      0.00      1.00      0.00      0.00      0.00      16.0\n",
      "          3       0.00      0.00      1.00      0.00      0.00      0.00      14.0\n",
      "          4       0.00      0.00      1.00      0.00      0.00      0.00       7.0\n",
      "          5       0.00      0.00      1.00      0.00      0.00      0.00       7.0\n",
      "          6       0.00      0.00      1.00      0.00      0.00      0.00       8.0\n",
      "          7       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "          8       0.00      0.00      1.00      0.00      0.00      0.00      11.0\n",
      "          9       0.00      0.00      1.00      0.00      0.00      0.00       5.0\n",
      "         10       0.00      0.00      1.00      0.00      0.00      0.00       4.0\n",
      "         11       0.00      0.00      1.00      0.00      0.00      0.00       5.0\n",
      "         12       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         13       0.00      0.00      1.00      0.00      0.00      0.00       4.0\n",
      "         14       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         15       0.00      0.00      1.00      0.00      0.00      0.00       4.0\n",
      "         16       0.00      0.00      1.00      0.00      0.00      0.00       5.0\n",
      "         17       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         18       0.00      0.00      1.00      0.00      0.00      0.00       6.0\n",
      "         19       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         20       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         21       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         22       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         23       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         25       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         26       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         27       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         28       0.00      0.00      1.00      0.00      0.00      0.00       6.0\n",
      "         29       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         30       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         31       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         32       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         33       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         34       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         36       0.00      0.00      1.00      0.00      0.00      0.00       4.0\n",
      "         37       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         39       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         40       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         42       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         43       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         44       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         45       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         46       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         47       0.00      0.00      1.00      0.00      0.00      0.00       4.0\n",
      "         49       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         50       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         52       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         53       0.00      0.00      1.00      0.00      0.00      0.00       6.0\n",
      "         54       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         55       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         57       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         60       0.00      0.00      1.00      0.00      0.00      0.00       4.0\n",
      "         61       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         62       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         63       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         64       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         65       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         66       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         67       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         68       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         69       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         71       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         74       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         75       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         77       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         78       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         80       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         81       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         82       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         85       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         86       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         87       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         88       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         90       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         91       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         92       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         93       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         94       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         96       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         97       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        101       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "        102       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        103       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        105       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        106       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        107       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        111       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        112       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        117       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        120       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        121       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        125       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        126       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        131       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "        133       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        141       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        142       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        143       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        145       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        146       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        150       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        151       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        158       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        164       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        166       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        167       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        169       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        170       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        172       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        174       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        176       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        177       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        187       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        194       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        196       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        200       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        215       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        223       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        228       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        229       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        231       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        238       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        239       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        247       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        257       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        270       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        276       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        297       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        315       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        316       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        317       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        319       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        345       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        346       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        367       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        369       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        380       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        385       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        394       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        395       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        414       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        429       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        458       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        466       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        505       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        513       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        544       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        579       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        580       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        587       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        732       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        736       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        764       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        768       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        772       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        776       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        797       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        878       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        924       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        925       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        935       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        950       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        971       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        976       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1008       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1013       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1038       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1106       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1145       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1215       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1383       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1409       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1432       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1989       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       2011       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       2057       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       2086       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       2394       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       2483       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       3281       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       3734       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       7310       0.00      0.00      0.97      0.00      0.00      0.00       0.0\n",
      "       8852       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       8874       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       9952       0.00      0.00      0.30      0.00      0.00      0.00       0.0\n",
      "      10081       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "      18684       0.00      0.00      0.97      0.00      0.00      0.00       0.0\n",
      "      21126       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "      23021       0.00      0.00      0.77      0.00      0.00      0.00       0.0\n",
      "      23709       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "      29232       0.00      0.00      0.99      0.00      0.00      0.00       0.0\n",
      "\n",
      "avg / total       0.00      0.00      1.00      0.00      0.00      0.00     378.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7324b9",
   "metadata": {},
   "source": [
    "### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4572eeb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30592\\3551349272.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampling_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mnns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[0;32m    326\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    727\u001b[0m             raise ValueError(\n\u001b[0;32m    728\u001b[0m                 \u001b[1;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m                 \u001b[1;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m             )\n\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "# Resample the training data with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_resampled, y_resampled = SMOTE(random_state=1, sampling_strategy='auto').fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30724c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Prediction\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe29b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0924fb96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87126b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3322d54",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5fe3fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Violent_Offenses': 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids(random_state=1)\n",
    "\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d1dbff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=78)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', random_state=78)\n",
    "\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d82adb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Prediction\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "560249d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30189a66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 3, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c179026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.00      0.00      1.00      0.00      0.00      0.00      19.0\n",
      "          1       0.00      0.00      1.00      0.00      0.00      0.00      17.0\n",
      "          2       0.00      0.00      1.00      0.00      0.00      0.00      16.0\n",
      "          3       0.00      0.00      1.00      0.00      0.00      0.00      14.0\n",
      "          4       0.00      0.00      1.00      0.00      0.00      0.00       7.0\n",
      "          5       0.00      0.00      1.00      0.00      0.00      0.00       7.0\n",
      "          6       0.00      0.00      1.00      0.00      0.00      0.00       8.0\n",
      "          7       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "          8       0.00      0.00      1.00      0.00      0.00      0.00      11.0\n",
      "          9       0.00      0.00      1.00      0.00      0.00      0.00       5.0\n",
      "         10       0.00      0.00      1.00      0.00      0.00      0.00       4.0\n",
      "         11       0.00      0.00      1.00      0.00      0.00      0.00       5.0\n",
      "         12       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         13       0.00      0.00      1.00      0.00      0.00      0.00       4.0\n",
      "         14       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         15       0.00      0.00      1.00      0.00      0.00      0.00       4.0\n",
      "         16       0.00      0.00      1.00      0.00      0.00      0.00       5.0\n",
      "         17       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         18       0.00      0.00      1.00      0.00      0.00      0.00       6.0\n",
      "         19       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         20       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         21       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         22       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         23       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         25       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         26       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         27       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         28       0.00      0.00      1.00      0.00      0.00      0.00       6.0\n",
      "         29       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         30       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         31       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         32       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         33       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         34       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         36       0.00      0.00      1.00      0.00      0.00      0.00       4.0\n",
      "         37       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         39       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         40       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         42       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         43       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         44       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         45       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         46       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         47       0.00      0.00      1.00      0.00      0.00      0.00       4.0\n",
      "         49       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         50       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         52       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         53       0.00      0.00      1.00      0.00      0.00      0.00       6.0\n",
      "         54       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         55       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         57       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         60       0.00      0.00      1.00      0.00      0.00      0.00       4.0\n",
      "         61       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         62       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         63       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         64       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         65       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         66       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         67       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         68       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         69       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         71       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "         74       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         75       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         77       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         78       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         80       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         81       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         82       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         85       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         86       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         87       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "         88       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         90       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         91       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         92       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         93       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         94       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         96       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "         97       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        101       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "        102       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        103       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        105       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        106       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        107       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        111       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        112       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        117       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        120       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        121       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        125       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        126       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        131       0.00      0.00      1.00      0.00      0.00      0.00       3.0\n",
      "        133       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        141       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        142       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        143       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        145       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        146       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        150       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        151       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        158       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        164       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        166       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        167       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        169       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        170       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        172       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        174       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        176       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        177       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        187       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        194       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        196       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        200       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        215       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        223       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        228       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        229       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        231       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        238       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        239       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        247       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        257       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        270       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        276       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        297       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        315       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        316       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        317       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        319       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        345       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        346       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        367       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        369       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        380       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        385       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        394       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        395       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        414       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        429       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        458       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        466       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        505       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        513       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        544       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        579       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        580       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        587       0.00      0.00      1.00      0.00      0.00      0.00       2.0\n",
      "        732       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        736       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        764       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        768       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        772       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        776       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        797       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        878       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        924       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        925       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        935       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        950       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        971       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "        976       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1008       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1013       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1038       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1106       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1145       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1215       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1383       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1409       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1432       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       1989       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       2011       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       2057       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       2086       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       2394       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       2483       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       3281       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       3734       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       7310       0.00      0.00      0.99      0.00      0.00      0.00       0.0\n",
      "       8852       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "       8874       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "      10081       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "      11840       0.00      0.00      0.15      0.00      0.00      0.00       0.0\n",
      "      18684       0.00      0.00      0.98      0.00      0.00      0.00       0.0\n",
      "      21126       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "      23021       0.00      0.00      0.88      0.00      0.00      0.00       0.0\n",
      "      23709       0.00      0.00      1.00      0.00      0.00      0.00       1.0\n",
      "      29232       0.00      0.00      0.99      0.00      0.00      0.00       0.0\n",
      "\n",
      "avg / total       0.00      0.00      1.00      0.00      0.00      0.00     378.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968573f5",
   "metadata": {},
   "source": [
    "## Combination (Over and Under) Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73773ee3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30592\\2826029196.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msmote_enn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmote_enn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\imblearn\\combine\\_smote_enn.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling_strategy_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmote_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menn_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mnns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[0;32m    326\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    727\u001b[0m             raise ValueError(\n\u001b[0;32m    728\u001b[0m                 \u001b[1;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m                 \u001b[1;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m             )\n\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b798f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Prediction\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845c90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58603b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1735581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe9e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f33b5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
